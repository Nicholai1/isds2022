{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-23T15:30:03.634114Z",
     "start_time": "2017-08-23T15:30:03.629294Z"
    }
   },
   "source": [
    "# Videos and Exercises for Session 11: Regression and Regularization\n",
    "\n",
    "In this combined teaching module and exercise set, you will learn about linear regression models in a machine learning perspective. We will see how overfitting can arise and how we can tackle it with a modification of the linear regression model.\n",
    "\n",
    "The structure of this notebook is as follows:\n",
    "1. Linear Regression Mechanics\n",
    "2. Overfitting and Underfitting in Linear Regression\n",
    "    - Exploring Overfitting in Linear Regression\n",
    "    - A Cure for Overfitting in Linear Regression\n",
    "3. Modelling Houseprices (Exercise)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Packages\n",
    "First, we need to import our standard stuff. Notice that we are not interested in seeing the convergence warning in scikit-learn, so we suppress them for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "warnings.filterwarnings(action='ignore', category=ConvergenceWarning)\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from statistics import stdev\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1: Linear Regression Mechanics\n",
    "## Implementing and evaluating the gradient decent \n",
    " \n",
    "Normally we use OLS to estimate linear regression models, but this is only way of solving the problem of minimizing the least squares problem (that minimizes the sum of squared errors). In the video below we show how to implement gradient descent below and compare it along with other approximate solutions to OLS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "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",
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"640\"\n",
       "            height=\"360\"\n",
       "            src=\"https://www.youtube.com/embed/XidjsIseyv0\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.YouTubeVideo at 0x7fbe408cb2e0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import YouTubeVideo\n",
    "YouTubeVideo('XidjsIseyv0', width=640, height=360)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We continue straight to an exercise where you are to implement a new estimator that we code up from scratch. We solve the numerical optimization using the gradient decent algorithm. This will be very similar to what we just saw in the video, but we will pay a bit more attention to each step in the process.\n",
    "\n",
    "Using our algorithm, we will fit it to some data, and compare our own solution to the standard solution from `sklearn`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Ex. 11.1.0**: Import the dataset `tips` from the `seaborn`.\n",
    "\n",
    "\n",
    "*Hint*: use the `load_dataset` method in seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6e812556b5b6774ba76a4a1ccb89a169",
     "grade": false,
     "grade_id": "cell-2dd56f36f76bce57",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "tips = sns.load_dataset('tips')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Ex. 11.1.1**: Convert non-numeric variables to dummy variables for each category (remember to leave one column out for each catagorical variable, so you have a reference). Restructure the data so we get a dataset `y` containing the variable tip, and a dataset `X` containing the \n",
    "features. \n",
    "\n",
    "> *Hint*: You might want to use the `get_dummies` method in pandas, with the `drop_first = True` parameter. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2ce55b897e3acd6727916dffe21150f6",
     "grade": false,
     "grade_id": "cell-2e42eb4f59160bed",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "y = tips['tip']\n",
    "x = tips[['total_bill','size']]\n",
    "x = pd.get_dummies(tips, drop_first = True)\n",
    "x = x.drop(columns =['tip'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Ex. 11.1.2**: Divide the features and target into test and train data. Make the split 50 pct. of each. The split data should be called `X_train`, `X_test`, `y_train`, `y_test`.\n",
    "\n",
    "> *Hint*: You may use `train_test_split` in `sklearn.model_selection`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "eb3675bb8e21477c6f5c76f67a3a5ed0",
     "grade": false,
     "grade_id": "cell-ba197171f1b2bfef",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "...     x, y, test_size=0.50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Ex. 11.1.3**: Normalize your features by converting to zero mean and one std. deviation.\n",
    "\n",
    "> *Hint*: Take a look at `StandardScaler` in `sklearn.preprocessing`. If in doubt about which distribution to scale, you may read [this post](https://stats.stackexchange.com/questions/174823/how-to-apply-standardization-normalization-to-train-and-testset-if-prediction-i)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5a4d5e2ed6417f454e18385a2804a19b",
     "grade": false,
     "grade_id": "cell-8ab591d5927be1d5",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2.09137235e+00,  1.29388081e+00, -5.96284794e-01,\n",
       "         7.24568837e-01, -2.64906471e-01,  1.43178211e+00,\n",
       "        -7.11458249e-01,  6.46996639e-01],\n",
       "       [-4.69915578e-01, -6.91697286e-01,  1.67705098e+00,\n",
       "        -1.38013112e+00,  3.77491722e+00, -6.98430296e-01,\n",
       "        -7.11458249e-01, -1.54560308e+00],\n",
       "       [ 3.86428637e-01,  1.29388081e+00, -5.96284794e-01,\n",
       "        -1.38013112e+00, -2.64906471e-01,  1.43178211e+00,\n",
       "        -7.11458249e-01,  6.46996639e-01],\n",
       "       [ 1.40565673e-03,  1.29388081e+00, -5.96284794e-01,\n",
       "        -1.38013112e+00, -2.64906471e-01, -6.98430296e-01,\n",
       "        -7.11458249e-01, -1.54560308e+00],\n",
       "       [-6.67959007e-01, -6.91697286e-01, -5.96284794e-01,\n",
       "        -1.38013112e+00, -2.64906471e-01, -6.98430296e-01,\n",
       "         1.40556386e+00,  6.46996639e-01],\n",
       "       [ 1.31468806e+00,  1.29388081e+00, -5.96284794e-01,\n",
       "         7.24568837e-01, -2.64906471e-01, -6.98430296e-01,\n",
       "         1.40556386e+00,  6.46996639e-01],\n",
       "       [ 7.11080928e-02, -6.91697286e-01, -5.96284794e-01,\n",
       "         7.24568837e-01, -2.64906471e-01, -6.98430296e-01,\n",
       "        -7.11458249e-01, -1.54560308e+00],\n",
       "       [-2.30935797e-01,  1.29388081e+00, -5.96284794e-01,\n",
       "         7.24568837e-01, -2.64906471e-01, -6.98430296e-01,\n",
       "         1.40556386e+00,  6.46996639e-01],\n",
       "       [-5.34086075e-01, -6.91697286e-01, -5.96284794e-01,\n",
       "        -1.38013112e+00, -2.64906471e-01, -6.98430296e-01,\n",
       "         1.40556386e+00,  6.46996639e-01],\n",
       "       [ 8.46685993e-01,  3.01091760e-01,  1.67705098e+00,\n",
       "        -1.38013112e+00, -2.64906471e-01,  1.43178211e+00,\n",
       "        -7.11458249e-01,  6.46996639e-01],\n",
       "       [ 8.76558465e-01, -6.91697286e-01, -5.96284794e-01,\n",
       "        -1.38013112e+00, -2.64906471e-01, -6.98430296e-01,\n",
       "        -7.11458249e-01, -1.54560308e+00],\n",
       "       [-1.19190622e-01, -6.91697286e-01, -5.96284794e-01,\n",
       "        -1.38013112e+00, -2.64906471e-01, -6.98430296e-01,\n",
       "        -7.11458249e-01, -1.54560308e+00],\n",
       "       [ 1.93537166e+00,  1.29388081e+00, -5.96284794e-01,\n",
       "        -1.38013112e+00, -2.64906471e-01,  1.43178211e+00,\n",
       "        -7.11458249e-01,  6.46996639e-01],\n",
       "       [-1.29970648e+00, -6.91697286e-01, -5.96284794e-01,\n",
       "         7.24568837e-01, -2.64906471e-01, -6.98430296e-01,\n",
       "         1.40556386e+00,  6.46996639e-01],\n",
       "       [-5.63958547e-01, -6.91697286e-01, -5.96284794e-01,\n",
       "         7.24568837e-01, -2.64906471e-01, -6.98430296e-01,\n",
       "         1.40556386e+00,  6.46996639e-01],\n",
       "       [ 1.36226274e+00, -6.91697286e-01, -5.96284794e-01,\n",
       "        -1.38013112e+00, -2.64906471e-01,  1.43178211e+00,\n",
       "        -7.11458249e-01,  6.46996639e-01],\n",
       "       [-7.85236122e-01, -6.91697286e-01, -5.96284794e-01,\n",
       "        -1.38013112e+00,  3.77491722e+00, -6.98430296e-01,\n",
       "        -7.11458249e-01, -1.54560308e+00],\n",
       "       [ 2.85747340e-01,  3.01091760e-01, -5.96284794e-01,\n",
       "        -1.38013112e+00, -2.64906471e-01, -6.98430296e-01,\n",
       "         1.40556386e+00,  6.46996639e-01],\n",
       "       [ 5.28046285e-01,  1.29388081e+00, -5.96284794e-01,\n",
       "         7.24568837e-01, -2.64906471e-01, -6.98430296e-01,\n",
       "         1.40556386e+00,  6.46996639e-01],\n",
       "       [-3.23872378e-01,  3.01091760e-01, -5.96284794e-01,\n",
       "         7.24568837e-01, -2.64906471e-01,  1.43178211e+00,\n",
       "        -7.11458249e-01,  6.46996639e-01],\n",
       "       [-3.57064015e-01, -6.91697286e-01, -5.96284794e-01,\n",
       "         7.24568837e-01, -2.64906471e-01, -6.98430296e-01,\n",
       "        -7.11458249e-01, -1.54560308e+00],\n",
       "       [ 3.05946174e+00,  3.27945890e+00, -5.96284794e-01,\n",
       "         7.24568837e-01, -2.64906471e-01, -6.98430296e-01,\n",
       "         1.40556386e+00,  6.46996639e-01],\n",
       "       [-7.44544627e-03,  1.29388081e+00, -5.96284794e-01,\n",
       "         7.24568837e-01, -2.64906471e-01,  1.43178211e+00,\n",
       "        -7.11458249e-01,  6.46996639e-01],\n",
       "       [-1.10719499e+00, -6.91697286e-01, -5.96284794e-01,\n",
       "         7.24568837e-01, -2.64906471e-01,  1.43178211e+00,\n",
       "        -7.11458249e-01,  6.46996639e-01],\n",
       "       [-7.88555286e-01, -6.91697286e-01,  1.67705098e+00,\n",
       "         7.24568837e-01, -2.64906471e-01, -6.98430296e-01,\n",
       "         1.40556386e+00,  6.46996639e-01],\n",
       "       [-7.42086995e-01, -6.91697286e-01, -5.96284794e-01,\n",
       "         7.24568837e-01, -2.64906471e-01, -6.98430296e-01,\n",
       "         1.40556386e+00,  6.46996639e-01],\n",
       "       [-1.12710998e+00, -6.91697286e-01,  1.67705098e+00,\n",
       "         7.24568837e-01, -2.64906471e-01, -6.98430296e-01,\n",
       "        -7.11458249e-01, -1.54560308e+00],\n",
       "       [-2.07701652e-01,  3.01091760e-01,  1.67705098e+00,\n",
       "         7.24568837e-01, -2.64906471e-01, -6.98430296e-01,\n",
       "        -7.11458249e-01, -1.54560308e+00],\n",
       "       [-2.73604280e-02, -6.91697286e-01,  1.67705098e+00,\n",
       "         7.24568837e-01, -2.64906471e-01, -6.98430296e-01,\n",
       "        -7.11458249e-01, -1.54560308e+00],\n",
       "       [ 5.26939897e-01, -6.91697286e-01,  1.67705098e+00,\n",
       "        -1.38013112e+00, -2.64906471e-01,  1.43178211e+00,\n",
       "        -7.11458249e-01,  6.46996639e-01],\n",
       "       [ 3.49917837e-01, -6.91697286e-01, -5.96284794e-01,\n",
       "         7.24568837e-01, -2.64906471e-01, -6.98430296e-01,\n",
       "         1.40556386e+00,  6.46996639e-01],\n",
       "       [ 5.45122747e-02, -6.91697286e-01, -5.96284794e-01,\n",
       "        -1.38013112e+00,  3.77491722e+00, -6.98430296e-01,\n",
       "        -7.11458249e-01,  6.46996639e-01],\n",
       "       [-2.90680742e-01, -6.91697286e-01, -5.96284794e-01,\n",
       "        -1.38013112e+00, -2.64906471e-01, -6.98430296e-01,\n",
       "         1.40556386e+00,  6.46996639e-01],\n",
       "       [-1.46787744e+00, -6.91697286e-01, -5.96284794e-01,\n",
       "        -1.38013112e+00, -2.64906471e-01, -6.98430296e-01,\n",
       "         1.40556386e+00,  6.46996639e-01],\n",
       "       [ 2.93492056e-01,  1.29388081e+00, -5.96284794e-01,\n",
       "        -1.38013112e+00, -2.64906471e-01, -6.98430296e-01,\n",
       "         1.40556386e+00,  6.46996639e-01],\n",
       "       [-2.74084924e-01, -6.91697286e-01, -5.96284794e-01,\n",
       "         7.24568837e-01, -2.64906471e-01, -6.98430296e-01,\n",
       "         1.40556386e+00,  6.46996639e-01],\n",
       "       [-3.02851009e-01, -6.91697286e-01, -5.96284794e-01,\n",
       "         7.24568837e-01, -2.64906471e-01,  1.43178211e+00,\n",
       "        -7.11458249e-01,  6.46996639e-01],\n",
       "       [-1.43911136e+00, -6.91697286e-01, -5.96284794e-01,\n",
       "         7.24568837e-01, -2.64906471e-01, -6.98430296e-01,\n",
       "        -7.11458249e-01, -1.54560308e+00],\n",
       "       [-3.01989477e-03, -6.91697286e-01, -5.96284794e-01,\n",
       "        -1.38013112e+00, -2.64906471e-01,  1.43178211e+00,\n",
       "        -7.11458249e-01,  6.46996639e-01],\n",
       "       [-2.51476523e-02, -6.91697286e-01, -5.96284794e-01,\n",
       "        -1.38013112e+00, -2.64906471e-01,  1.43178211e+00,\n",
       "        -7.11458249e-01,  6.46996639e-01],\n",
       "       [ 1.63111500e+00,  1.29388081e+00,  1.67705098e+00,\n",
       "         7.24568837e-01, -2.64906471e-01, -6.98430296e-01,\n",
       "         1.40556386e+00,  6.46996639e-01],\n",
       "       [ 4.46173582e-01,  1.29388081e+00, -5.96284794e-01,\n",
       "         7.24568837e-01, -2.64906471e-01, -6.98430296e-01,\n",
       "         1.40556386e+00,  6.46996639e-01],\n",
       "       [-7.82542702e-02, -6.91697286e-01,  1.67705098e+00,\n",
       "        -1.38013112e+00, -2.64906471e-01, -6.98430296e-01,\n",
       "        -7.11458249e-01, -1.54560308e+00],\n",
       "       [-2.99531845e-01,  1.29388081e+00, -5.96284794e-01,\n",
       "         7.24568837e-01, -2.64906471e-01,  1.43178211e+00,\n",
       "        -7.11458249e-01,  6.46996639e-01],\n",
       "       [ 5.45122747e-02,  3.01091760e-01, -5.96284794e-01,\n",
       "         7.24568837e-01, -2.64906471e-01, -6.98430296e-01,\n",
       "         1.40556386e+00,  6.46996639e-01],\n",
       "       [ 2.21639418e+00, -6.91697286e-01, -5.96284794e-01,\n",
       "        -1.38013112e+00, -2.64906471e-01, -6.98430296e-01,\n",
       "         1.40556386e+00,  6.46996639e-01],\n",
       "       [ 2.28720301e+00,  2.28666985e+00, -5.96284794e-01,\n",
       "         7.24568837e-01, -2.64906471e-01, -6.98430296e-01,\n",
       "        -7.11458249e-01, -1.54560308e+00],\n",
       "       [ 8.88728732e-01,  3.01091760e-01, -5.96284794e-01,\n",
       "         7.24568837e-01, -2.64906471e-01, -6.98430296e-01,\n",
       "         1.40556386e+00,  6.46996639e-01],\n",
       "       [-1.32847257e+00, -6.91697286e-01,  1.67705098e+00,\n",
       "         7.24568837e-01, -2.64906471e-01, -6.98430296e-01,\n",
       "        -7.11458249e-01, -1.54560308e+00],\n",
       "       [-2.02169712e-01,  3.01091760e-01, -5.96284794e-01,\n",
       "         7.24568837e-01, -2.64906471e-01,  1.43178211e+00,\n",
       "        -7.11458249e-01,  6.46996639e-01],\n",
       "       [-3.60383178e-01,  3.01091760e-01, -5.96284794e-01,\n",
       "         7.24568837e-01, -2.64906471e-01, -6.98430296e-01,\n",
       "         1.40556386e+00,  6.46996639e-01],\n",
       "       [-1.09170556e+00, -6.91697286e-01,  1.67705098e+00,\n",
       "         7.24568837e-01, -2.64906471e-01, -6.98430296e-01,\n",
       "        -7.11458249e-01, -1.54560308e+00],\n",
       "       [-1.09834389e+00, -6.91697286e-01,  1.67705098e+00,\n",
       "        -1.38013112e+00, -2.64906471e-01,  1.43178211e+00,\n",
       "        -7.11458249e-01,  6.46996639e-01],\n",
       "       [-5.34086075e-01,  3.01091760e-01, -5.96284794e-01,\n",
       "        -1.38013112e+00, -2.64906471e-01,  1.43178211e+00,\n",
       "        -7.11458249e-01,  6.46996639e-01],\n",
       "       [-4.83817976e-02,  3.01091760e-01, -5.96284794e-01,\n",
       "         7.24568837e-01, -2.64906471e-01,  1.43178211e+00,\n",
       "        -7.11458249e-01,  6.46996639e-01],\n",
       "       [ 3.07052562e+00,  1.29388081e+00, -5.96284794e-01,\n",
       "         7.24568837e-01, -2.64906471e-01,  1.43178211e+00,\n",
       "        -7.11458249e-01,  6.46996639e-01],\n",
       "       [-4.67702802e-01,  3.01091760e-01, -5.96284794e-01,\n",
       "         7.24568837e-01, -2.64906471e-01, -6.98430296e-01,\n",
       "         1.40556386e+00,  6.46996639e-01],\n",
       "       [-9.87705103e-01, -6.91697286e-01, -5.96284794e-01,\n",
       "        -1.38013112e+00, -2.64906471e-01,  1.43178211e+00,\n",
       "        -7.11458249e-01,  6.46996639e-01],\n",
       "       [-9.39024037e-01, -6.91697286e-01, -5.96284794e-01,\n",
       "        -1.38013112e+00,  3.77491722e+00, -6.98430296e-01,\n",
       "        -7.11458249e-01,  6.46996639e-01],\n",
       "       [ 4.45547838e-02, -6.91697286e-01,  1.67705098e+00,\n",
       "         7.24568837e-01, -2.64906471e-01,  1.43178211e+00,\n",
       "        -7.11458249e-01,  6.46996639e-01],\n",
       "       [-4.52213372e-01, -6.91697286e-01,  1.67705098e+00,\n",
       "         7.24568837e-01, -2.64906471e-01, -6.98430296e-01,\n",
       "        -7.11458249e-01, -1.54560308e+00],\n",
       "       [ 2.48130153e-01, -6.91697286e-01, -5.96284794e-01,\n",
       "         7.24568837e-01, -2.64906471e-01, -6.98430296e-01,\n",
       "        -7.11458249e-01, -1.54560308e+00],\n",
       "       [ 1.30853038e-01, -6.91697286e-01, -5.96284794e-01,\n",
       "         7.24568837e-01, -2.64906471e-01,  1.43178211e+00,\n",
       "        -7.11458249e-01,  6.46996639e-01],\n",
       "       [-1.01093925e+00, -6.91697286e-01,  1.67705098e+00,\n",
       "         7.24568837e-01, -2.64906471e-01, -6.98430296e-01,\n",
       "        -7.11458249e-01, -1.54560308e+00],\n",
       "       [-7.27703953e-01, -6.91697286e-01, -5.96284794e-01,\n",
       "         7.24568837e-01, -2.64906471e-01, -6.98430296e-01,\n",
       "         1.40556386e+00,  6.46996639e-01],\n",
       "       [-3.17859795e-02, -6.91697286e-01, -5.96284794e-01,\n",
       "         7.24568837e-01, -2.64906471e-01,  1.43178211e+00,\n",
       "        -7.11458249e-01,  6.46996639e-01],\n",
       "       [ 3.07716395e+00,  1.29388081e+00, -5.96284794e-01,\n",
       "         7.24568837e-01, -2.64906471e-01,  1.43178211e+00,\n",
       "        -7.11458249e-01,  6.46996639e-01],\n",
       "       [ 5.94429557e-01,  1.29388081e+00, -5.96284794e-01,\n",
       "        -1.38013112e+00, -2.64906471e-01,  1.43178211e+00,\n",
       "        -7.11458249e-01,  6.46996639e-01],\n",
       "       [-1.05076921e+00, -6.91697286e-01, -5.96284794e-01,\n",
       "        -1.38013112e+00, -2.64906471e-01,  1.43178211e+00,\n",
       "        -7.11458249e-01,  6.46996639e-01],\n",
       "       [-6.34767371e-01, -6.91697286e-01, -5.96284794e-01,\n",
       "         7.24568837e-01, -2.64906471e-01, -6.98430296e-01,\n",
       "         1.40556386e+00,  6.46996639e-01],\n",
       "       [-8.91449358e-01, -6.91697286e-01, -5.96284794e-01,\n",
       "         7.24568837e-01,  3.77491722e+00, -6.98430296e-01,\n",
       "        -7.11458249e-01,  6.46996639e-01],\n",
       "       [-5.57320220e-01, -6.91697286e-01, -5.96284794e-01,\n",
       "        -1.38013112e+00, -2.64906471e-01, -6.98430296e-01,\n",
       "        -7.11458249e-01, -1.54560308e+00],\n",
       "       [ 8.44473217e-01,  2.28666985e+00, -5.96284794e-01,\n",
       "        -1.38013112e+00, -2.64906471e-01,  1.43178211e+00,\n",
       "        -7.11458249e-01,  6.46996639e-01],\n",
       "       [-6.06001286e-01, -6.91697286e-01, -5.96284794e-01,\n",
       "         7.24568837e-01, -2.64906471e-01, -6.98430296e-01,\n",
       "         1.40556386e+00,  6.46996639e-01],\n",
       "       [-7.13320910e-01, -6.91697286e-01, -5.96284794e-01,\n",
       "         7.24568837e-01, -2.64906471e-01, -6.98430296e-01,\n",
       "         1.40556386e+00,  6.46996639e-01],\n",
       "       [-7.75278631e-01, -6.91697286e-01, -5.96284794e-01,\n",
       "        -1.38013112e+00, -2.64906471e-01, -6.98430296e-01,\n",
       "        -7.11458249e-01, -1.54560308e+00],\n",
       "       [ 1.23834730e+00,  1.29388081e+00, -5.96284794e-01,\n",
       "         7.24568837e-01, -2.64906471e-01, -6.98430296e-01,\n",
       "         1.40556386e+00,  6.46996639e-01],\n",
       "       [ 1.56362534e+00,  1.29388081e+00, -5.96284794e-01,\n",
       "        -1.38013112e+00, -2.64906471e-01, -6.98430296e-01,\n",
       "         1.40556386e+00,  6.46996639e-01],\n",
       "       [ 1.69417910e+00,  3.01091760e-01,  1.67705098e+00,\n",
       "         7.24568837e-01, -2.64906471e-01,  1.43178211e+00,\n",
       "        -7.11458249e-01,  6.46996639e-01],\n",
       "       [-9.56726243e-01, -6.91697286e-01,  1.67705098e+00,\n",
       "         7.24568837e-01, -2.64906471e-01, -6.98430296e-01,\n",
       "        -7.11458249e-01, -1.54560308e+00],\n",
       "       [-1.07842891e+00, -6.91697286e-01, -5.96284794e-01,\n",
       "         7.24568837e-01, -2.64906471e-01,  1.43178211e+00,\n",
       "        -7.11458249e-01,  6.46996639e-01],\n",
       "       [-8.28385249e-01, -6.91697286e-01, -5.96284794e-01,\n",
       "         7.24568837e-01, -2.64906471e-01, -6.98430296e-01,\n",
       "        -7.11458249e-01, -1.54560308e+00],\n",
       "       [ 2.74746036e+00,  3.01091760e-01, -5.96284794e-01,\n",
       "        -1.38013112e+00, -2.64906471e-01, -6.98430296e-01,\n",
       "         1.40556386e+00,  6.46996639e-01],\n",
       "       [ 3.94173352e-01,  1.29388081e+00,  1.67705098e+00,\n",
       "         7.24568837e-01, -2.64906471e-01, -6.98430296e-01,\n",
       "        -7.11458249e-01, -1.54560308e+00],\n",
       "       [-1.92212221e-01, -6.91697286e-01,  1.67705098e+00,\n",
       "         7.24568837e-01, -2.64906471e-01, -6.98430296e-01,\n",
       "        -7.11458249e-01,  6.46996639e-01],\n",
       "       [ 1.08725281e-01,  1.29388081e+00, -5.96284794e-01,\n",
       "         7.24568837e-01, -2.64906471e-01, -6.98430296e-01,\n",
       "         1.40556386e+00,  6.46996639e-01],\n",
       "       [-1.59020585e-01, -6.91697286e-01, -5.96284794e-01,\n",
       "         7.24568837e-01, -2.64906471e-01, -6.98430296e-01,\n",
       "        -7.11458249e-01, -1.54560308e+00],\n",
       "       [-9.85492327e-01, -6.91697286e-01, -5.96284794e-01,\n",
       "         7.24568837e-01, -2.64906471e-01,  1.43178211e+00,\n",
       "        -7.11458249e-01,  6.46996639e-01],\n",
       "       [-8.31704413e-01, -6.91697286e-01,  1.67705098e+00,\n",
       "        -1.38013112e+00, -2.64906471e-01, -6.98430296e-01,\n",
       "        -7.11458249e-01, -1.54560308e+00],\n",
       "       [-4.64383638e-01, -6.91697286e-01,  1.67705098e+00,\n",
       "        -1.38013112e+00,  3.77491722e+00, -6.98430296e-01,\n",
       "        -7.11458249e-01,  6.46996639e-01],\n",
       "       [ 5.57918758e-01,  1.29388081e+00, -5.96284794e-01,\n",
       "         7.24568837e-01, -2.64906471e-01, -6.98430296e-01,\n",
       "         1.40556386e+00,  6.46996639e-01],\n",
       "       [-6.29235432e-01, -6.91697286e-01,  1.67705098e+00,\n",
       "         7.24568837e-01, -2.64906471e-01, -6.98430296e-01,\n",
       "         1.40556386e+00,  6.46996639e-01],\n",
       "       [-4.95362499e-01,  3.01091760e-01, -5.96284794e-01,\n",
       "         7.24568837e-01, -2.64906471e-01,  1.43178211e+00,\n",
       "        -7.11458249e-01,  6.46996639e-01],\n",
       "       [ 5.19195182e-01, -6.91697286e-01, -5.96284794e-01,\n",
       "        -1.38013112e+00, -2.64906471e-01,  1.43178211e+00,\n",
       "        -7.11458249e-01,  6.46996639e-01],\n",
       "       [-2.46425227e-01,  1.29388081e+00, -5.96284794e-01,\n",
       "        -1.38013112e+00, -2.64906471e-01,  1.43178211e+00,\n",
       "        -7.11458249e-01,  6.46996639e-01],\n",
       "       [-1.03417339e+00, -6.91697286e-01,  1.67705098e+00,\n",
       "         7.24568837e-01, -2.64906471e-01, -6.98430296e-01,\n",
       "        -7.11458249e-01, -1.54560308e+00],\n",
       "       [ 7.03961957e-01,  1.29388081e+00, -5.96284794e-01,\n",
       "         7.24568837e-01, -2.64906471e-01, -6.98430296e-01,\n",
       "         1.40556386e+00,  6.46996639e-01],\n",
       "       [ 2.54768480e-01,  3.01091760e-01, -5.96284794e-01,\n",
       "         7.24568837e-01, -2.64906471e-01, -6.98430296e-01,\n",
       "        -7.11458249e-01, -1.54560308e+00],\n",
       "       [-2.98425457e-01, -6.91697286e-01, -5.96284794e-01,\n",
       "         7.24568837e-01, -2.64906471e-01,  1.43178211e+00,\n",
       "        -7.11458249e-01,  6.46996639e-01],\n",
       "       [-7.90768061e-01, -6.91697286e-01, -5.96284794e-01,\n",
       "         7.24568837e-01, -2.64906471e-01,  1.43178211e+00,\n",
       "        -7.11458249e-01,  6.46996639e-01],\n",
       "       [ 1.52490176e+00,  3.27945890e+00, -5.96284794e-01,\n",
       "         7.24568837e-01, -2.64906471e-01, -6.98430296e-01,\n",
       "        -7.11458249e-01, -1.54560308e+00],\n",
       "       [-1.34617477e+00, -6.91697286e-01,  1.67705098e+00,\n",
       "         7.24568837e-01, -2.64906471e-01, -6.98430296e-01,\n",
       "        -7.11458249e-01, -1.54560308e+00],\n",
       "       [ 1.34566692e+00, -6.91697286e-01, -5.96284794e-01,\n",
       "        -1.38013112e+00, -2.64906471e-01, -6.98430296e-01,\n",
       "        -7.11458249e-01, -1.54560308e+00],\n",
       "       [-6.40299310e-01, -6.91697286e-01,  1.67705098e+00,\n",
       "         7.24568837e-01, -2.64906471e-01,  1.43178211e+00,\n",
       "        -7.11458249e-01,  6.46996639e-01],\n",
       "       [-1.32072785e+00, -1.68448633e+00, -5.96284794e-01,\n",
       "        -1.38013112e+00,  3.77491722e+00, -6.98430296e-01,\n",
       "        -7.11458249e-01, -1.54560308e+00],\n",
       "       [-7.71478824e-02, -6.91697286e-01, -5.96284794e-01,\n",
       "         7.24568837e-01, -2.64906471e-01,  1.43178211e+00,\n",
       "        -7.11458249e-01,  6.46996639e-01],\n",
       "       [-1.12600359e+00,  3.01091760e-01, -5.96284794e-01,\n",
       "         7.24568837e-01, -2.64906471e-01, -6.98430296e-01,\n",
       "         1.40556386e+00,  6.46996639e-01],\n",
       "       [ 7.22770551e-01,  3.27945890e+00,  1.67705098e+00,\n",
       "         7.24568837e-01, -2.64906471e-01, -6.98430296e-01,\n",
       "        -7.11458249e-01, -1.54560308e+00],\n",
       "       [-2.61914657e-01,  3.01091760e-01,  1.67705098e+00,\n",
       "        -1.38013112e+00, -2.64906471e-01, -6.98430296e-01,\n",
       "         1.40556386e+00,  6.46996639e-01],\n",
       "       [ 1.18966623e+00,  3.01091760e-01, -5.96284794e-01,\n",
       "         7.24568837e-01, -2.64906471e-01,  1.43178211e+00,\n",
       "        -7.11458249e-01,  6.46996639e-01],\n",
       "       [-4.45575045e-01,  1.29388081e+00, -5.96284794e-01,\n",
       "         7.24568837e-01, -2.64906471e-01, -6.98430296e-01,\n",
       "         1.40556386e+00,  6.46996639e-01],\n",
       "       [ 4.63875788e-01, -6.91697286e-01, -5.96284794e-01,\n",
       "         7.24568837e-01, -2.64906471e-01, -6.98430296e-01,\n",
       "        -7.11458249e-01, -1.54560308e+00],\n",
       "       [ 7.39366369e-01,  1.29388081e+00, -5.96284794e-01,\n",
       "         7.24568837e-01, -2.64906471e-01, -6.98430296e-01,\n",
       "        -7.11458249e-01, -1.54560308e+00],\n",
       "       [-8.17321370e-01, -6.91697286e-01, -5.96284794e-01,\n",
       "         7.24568837e-01, -2.64906471e-01, -6.98430296e-01,\n",
       "         1.40556386e+00,  6.46996639e-01],\n",
       "       [-4.76553905e-01,  3.01091760e-01,  1.67705098e+00,\n",
       "         7.24568837e-01, -2.64906471e-01, -6.98430296e-01,\n",
       "         1.40556386e+00,  6.46996639e-01],\n",
       "       [-5.02000826e-01,  3.01091760e-01,  1.67705098e+00,\n",
       "         7.24568837e-01,  3.77491722e+00, -6.98430296e-01,\n",
       "        -7.11458249e-01, -1.54560308e+00],\n",
       "       [ 1.17576384e-01, -6.91697286e-01, -5.96284794e-01,\n",
       "         7.24568837e-01, -2.64906471e-01, -6.98430296e-01,\n",
       "         1.40556386e+00,  6.46996639e-01],\n",
       "       [ 1.25383673e+00, -6.91697286e-01, -5.96284794e-01,\n",
       "        -1.38013112e+00, -2.64906471e-01, -6.98430296e-01,\n",
       "         1.40556386e+00,  6.46996639e-01],\n",
       "       [-8.01831940e-01, -6.91697286e-01,  1.67705098e+00,\n",
       "        -1.38013112e+00, -2.64906471e-01,  1.43178211e+00,\n",
       "        -7.11458249e-01,  6.46996639e-01],\n",
       "       [-8.66002437e-01, -6.91697286e-01, -5.96284794e-01,\n",
       "         7.24568837e-01, -2.64906471e-01,  1.43178211e+00,\n",
       "        -7.11458249e-01,  6.46996639e-01],\n",
       "       [-2.49744391e-01, -6.91697286e-01,  1.67705098e+00,\n",
       "         7.24568837e-01, -2.64906471e-01, -6.98430296e-01,\n",
       "        -7.11458249e-01, -1.54560308e+00],\n",
       "       [-6.86767601e-01, -6.91697286e-01,  1.67705098e+00,\n",
       "        -1.38013112e+00, -2.64906471e-01,  1.43178211e+00,\n",
       "        -7.11458249e-01,  6.46996639e-01]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_std = StandardScaler().fit_transform(X_train)\n",
    "X_std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Ex. 11.1.4**: Make a function called `compute_error` to compute the prediction errors given input target `y_`, input features `X_` and input weights `w_`. You should use matrix multiplication.\n",
    ">\n",
    "> *Hint:* You can use the net-input fct. from yesterday.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b03c6de7d3488e832c4d3eb123587e17",
     "grade": false,
     "grade_id": "cell-a70101715bbbb443",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Ex. 11.1.5**: Make a function to update the weights given input target `y_`, input features `X_` and input weights `w_` as well as learning rate, $\\eta$, i.e. greek `eta`. You should use matrix multiplication."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INCLUDED IN ASSIGNMENT 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6cd45bb01781e944c41227e59873a6df",
     "grade": false,
     "grade_id": "cell-049443f1aafb8903",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Ex. 11.1.6**: Use the code below to initialize weights `w` at zero given feature set `X`. Notice how we include an extra weight that includes the bias term. Set the learning rate `eta` to 0.001. Make a loop with 50 iterations where you iteratively apply your weight updating function. \n",
    "\n",
    ">```python\n",
    "w = np.zeros(1+X_train.shape[1])\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INCLUDED IN ASSIGNMENT 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6308f5593a6e65ab57b86368ceef6669",
     "grade": false,
     "grade_id": "cell-74c4170d3d5fe322",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Ex. 11.1.7**: Make a function to compute the mean squared error. Alter the loop so it makes 100 iterations and computes the MSE for test and train after each iteration, plot these in one figure. \n",
    "\n",
    "> Hint: You can use the following code to check that your model works:\n",
    ">```python\n",
    "from sklearn.linear_model import LinearRegression\n",
    "reg = LinearRegression()\n",
    "reg.fit(X_train, y_train)\n",
    "assert((w[1:] - reg.coef_).sum() < 0.01)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "863ac125b673cb711cfc5269a05d1bf5",
     "grade": false,
     "grade_id": "cell-5cabc75ac6152434",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "\n",
    "pd.Series(MSE_train).plot()\n",
    "pd.Series(MSE_test).plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: Overfitting and Underfitting in Linear Regression \n",
    "\n",
    "## Exploring Overfitting in Linear Regression\n",
    "How does overfitting manifest itself in linear regression? In the video below we simulate what happens as make a better and better taylor approximation, i.e. we estimate a polynomial of higher and higher order. Two issues arise simultaneously - one is related to the number of parameters and the to the size of the parameters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "YouTubeVideo('NPARac_fnXw', width=640, height=360)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A Cure for Overfitting in Linear Regression\n",
    "\n",
    "How do we fix the two issues of excessively large weights/coefficients and too many spurious solutions? The video below provides a solution by directly incorporating these issues into the optimization problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "YouTubeVideo('SzPuyUCA5Mw', width=640, height=360)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above we tackled overfitting, but what about ***underfitting***? The video below shows how to address underfitting and also zooms in on some important details about regularization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "YouTubeVideo('64VOY77PHPk', width=640, height=360)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Ex. 11.2.1 (BONUS)**: Is it possible to add a penalty to our linear model above and solve this Lasso model with gradient descent? Is there a simple fix?\n",
    ">\n",
    "> *Hint:* Gradient descent essentially relies on a differentiable loss function (read more [here](https://stats.stackexchange.com/questions/177800/why-proximal-gradient-descent-instead-of-plain-subgradient-methods-for-lasso))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "04b4c075a4bad7561c1e03bf809f7faf",
     "grade": false,
     "grade_id": "cell-6aa146e9c530b2b4",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3: Modelling Houseprices\n",
    "In this example, we will try to predict houseprices using a lot of variable (or features as they are called in Machine Learning). We are going to work with Kaggle's dataset on house prices, see information [here](https://www.kaggle.com/c/house-prices-advanced-regression-techniques). Kaggle is an organization that hosts competitions in building predictive models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Ex. 11.3.0:** Load the california housing data with scikit-learn using the code below. Now:\n",
    "> 1. Inspect *cal_house*. How are the data stored?\n",
    "> 2. Create a pandas DataFrame called *X*, using `data`. Name the columns using `feature_names`.\n",
    "> 3. Crate a pandas Series called *y* using `target`.\n",
    "> 4. Make a train test split of equal size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "08ca919735b17dfbf96058bf07f4eeab",
     "grade": false,
     "grade_id": "cell-5f14e576643ac94c",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "cal_house = fetch_california_housing()    \n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "> **Ex.11.3.1**: Generate interactions between all features to third degree (make sure you **exclude** the bias/intercept term). How many variables are there? Will OLS fail? After making interactions, rescale the features to have zero mean, unit std. deviation. Should you use the distribution of the training data to rescale the test data?  \n",
    "\n",
    "> *Hint 1*: Try importing `PolynomialFeatures` from `sklearn.preprocessing`\n",
    "\n",
    "> *Hint 2*: If in doubt about which distribution to scale, you may read [this post](https://stats.stackexchange.com/questions/174823/how-to-apply-standardization-normalization-to-train-and-testset-if-prediction-i)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INCLUDED IN ASSIGNMENT 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ed00cd67cc7a2e431594d4cfe29da085",
     "grade": false,
     "grade_id": "cell-4aacfe9c22772c42",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Ex.11.3.2**: Estimate the Lasso model on the rescaled train data set, using values of $\\lambda$ in the range from $10^{-4}$ to $10^4$. For each $\\lambda$  calculate and save the Root Mean Squared Error (RMSE) for the rescaled test and train data. Take a look at the fitted coefficients for different sizes of $\\lambda$. What happens when $\\lambda$ increases? Why?\n",
    "\n",
    "> *Hint 1*: use `logspace` in numpy to create the range.\n",
    "\n",
    "> *Hint 2*: read about the `coef_` feature [here](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Lasso.html#sklearn.linear_model.Lasso).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INCLUDED IN ASSIGNMENT 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a5cb040dc44fd9a9f591f1193a1311ab",
     "grade": false,
     "grade_id": "cell-d981c29cec05057b",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Ex.11.3.3**: Make a plot with the lambdas on the x-axis and the RMSE measures on the y-axis. What happens to RMSE for train and test data as $\\lambda$ increases? The x-axis should be log scaled. Which one are we interested in minimizing? \n",
    "\n",
    "> Bonus: Can you find the lambda that gives the lowest MSE-test score?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INCLUDED IN ASSIGNMENT 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3469299a7668bf4275e2824d1d454144",
     "grade": false,
     "grade_id": "cell-5a2846b33750acbc",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# INCLUDED IN ASSIGNMENT 2# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  },
  "nav_menu": {},
  "toc": {
   "navigate_menu": true,
   "number_sections": false,
   "sideBar": true,
   "threshold": 6,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
